{
 "cells": [
  {
   "cell_type": "code",
   "id": "53392fb1-e34c-4921-8272-778e69266aa9",
   "metadata": {},
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"medicalai/ClinicalBERT\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"medicalai/ClinicalBERT\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b254743e-e2f8-4c51-9a2b-abae9975827f",
   "metadata": {},
   "source": [
    "# Example/dummy dataset: each sample contains a context, a question, and the ground-truth answer.\n",
    "dataset = load_dataset('json', data_files='dataset.json')['train']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def flatten_squad_like_data(example):\n",
    "    new_contexts = []\n",
    "    new_questions = []\n",
    "    new_answers = []\n",
    "\n",
    "    # Pull out the context just once\n",
    "    context_text = example[\"context\"]\n",
    "\n",
    "    for i in range(0,  len(context_text)):\n",
    "        # Each 'qa' within 'qas' is a question + list of answers\n",
    "        for qa in example[\"qas\"][i]:\n",
    "            answers = qa[\"answers\"]\n",
    "            for answer in answers:\n",
    "                new_contexts.append(context_text[i])\n",
    "                new_questions.append(qa[\"question\"])\n",
    "                new_answers.append({\"text\": answer[\"text\"], \"answer_start\": answer[\"answer_start\"]})\n",
    "\n",
    "    # Return the new, flattened lists. We rely on the 'map' call with 'batched=True'\n",
    "    # to automatically collate these into a single output set of columns.\n",
    "    return {\n",
    "        \"context\": new_contexts,\n",
    "        \"question\": new_questions,\n",
    "        \"answers\": new_answers\n",
    "    }"
   ],
   "id": "ff55994345880b4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ca9012e87ecc0204",
   "metadata": {},
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\"\n",
    "    For each example, tokenize the question and context together. Also, convert the raw answer span (start position in chars)\n",
    "    into token indices that the model will use as labels.\n",
    "    \"\"\"\n",
    "    # Tokenize question and context together.\n",
    "    inputs = tokenizer(examples[\"question\"], examples[\"context\"],\n",
    "                       truncation=True,\n",
    "                       padding=\"max_length\",\n",
    "                       max_length=256,\n",
    "                       return_offsets_mapping=True)\n",
    "\n",
    "    offset_mappings = inputs.pop(\"offset_mapping\")  # remove offsets (used only to align char indices)\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mappings):\n",
    "        # For the first answer in each example\n",
    "        answer = examples[\"answers\"][i][\"text\"]\n",
    "        answer_start_char = examples[\"answers\"][i][\"answer_start\"]\n",
    "        answer_end_char = answer_start_char + len(answer)\n",
    "\n",
    "        # Find the token indices corresponding to the start and end character positions.\n",
    "        start_index = None\n",
    "        end_index = None\n",
    "        for idx, (start_char, end_char) in enumerate(offsets):\n",
    "            if start_char <= answer_start_char < end_char:\n",
    "                start_index = idx\n",
    "            if start_char < answer_end_char <= end_char:\n",
    "                end_index = idx\n",
    "        # In some cases the answer might not align perfectly with a token span.\n",
    "        if start_index is None:\n",
    "            start_index = 0\n",
    "        if end_index is None:\n",
    "            end_index = len(offsets) - 1\n",
    "\n",
    "        start_positions.append(start_index)\n",
    "        end_positions.append(end_index)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs\n",
    "\n",
    "train_dataset = dataset.map(\n",
    "    flatten_squad_like_data,\n",
    "    batched=True,\n",
    "    remove_columns=dataset.column_names\n",
    ")\n",
    "\n",
    "# Tokenize the dataset.\n",
    "tokenized_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=train_dataset.column_names)\n",
    "\n",
    "# Set up training arguments.\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    #evaluation_strategy=\"no\",  # for simplicity we won't run an evaluation loop here\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=1,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=1,\n",
    "    save_steps=1000  # Save infrequently for the demo\n",
    ")\n",
    "\n",
    "# Initialize the Trainer with our model, training args, and tokenized dataset.\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    ")\n",
    "\n",
    "# Fine tune the model on the QA dataset.\n",
    "trainer.train()\n",
    "\n",
    "# -------------------------\n",
    "# Testing/inference step:\n",
    "# Let’s take a question and its context, then have the model extract an answer.\n",
    "\n",
    "question = \"What medication was given?\"\n",
    "context = \"In the hospital, the patient was administered amoxicillin for a bacterial infection.\"\n",
    "\n",
    "# Tokenize the input: note that for QA we combine question and context.\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=256)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# The model outputs 'start_logits' and 'end_logits', which represent the probability distribution\n",
    "# for the start and end of the answer span.\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "\n",
    "# Identify the most likely token positions for the start and end of the answer.\n",
    "start_index = torch.argmax(start_logits, dim=1).item()\n",
    "end_index = torch.argmax(end_logits, dim=1).item()\n",
    "\n",
    "# Decode the tokens corresponding to the predicted span.\n",
    "input_ids = inputs[\"input_ids\"].squeeze()\n",
    "answer_tokens = input_ids[start_index:(end_index + 1)]\n",
    "answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "# Output the results.\n",
    "print(\"Question:\", question)\n",
    "print(\"Predicted Answer:\", answer)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Get the contexts from the most similar questions\n",
   "id": "e20bb284c087c4a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "question1 = \"Que efeito tem o fármaco Rember em Alzheimer leve a moderado?\"\n",
    "context_CUF = \"\"\"A doença de Alzheimer constitui numa alteração neurológica que causa perda de memória e declínio cognitivo progressivos. Atualmente é o tipo de demência mais comum, sendo responsável por 60% a 80% dos casos nos Estados Unidos: em 2013, 6,8 milhões de pessoas foram diagnosticadas com demência, dos quais cinco milhões classificados como Alzheimer. Em 2050, espera-se que os números dupliquem.\n",
    "\n",
    "A doença de Alzheimer, de instalação insidiosa e progressão lenta, afeta, primeira e predominantemente, a memória episódica, com o doente a começar a ter dificuldades em lembrar-se de fragmentos recentes da sua vida (onde coloca os objetos, os recados, o que comeu no dia anterior, em que dia do mês está).\n",
    "\n",
    "Sintomas\n",
    "À perda de memória vão-se juntando lentamente outros sintomas característicos:\n",
    "\n",
    "Dificuldade em reconhecer pessoas\n",
    "Discurso mais pobre e entrecortado à procura de palavras\n",
    "Orientação em espaços fica cada vez mais difícil\n",
    "Com o tempo começam também a surgir as primeiras alterações do comportamento, sendo frequentes as alucinações visuais e a atividade delirante (o doente achar que o roubam ou perseguem), resultando em agitação e agressividade\n",
    "Este conjunto de dificuldades aumenta até ser suficiente para a pessoa deixar de viver de forma autónoma, tendo que ser ajudada em tarefas antes realizadas de forma natural, como cozinhar, vestir-se, lavar-se, lidar com eletrodomésticos ou dinheiro.\n",
    "\n",
    "Causas\n",
    "Tal como nos outros tipos de demência, a Alzheimer trata-se de uma doença neuro degenerativa, o que significa que há perda progressiva de células cerebrais ao longo do tempo: o tecido cerebral tem cada vez menos células nervosas e vão-se perdendo as conexões entre elas.\n",
    "\n",
    "Diagnóstico\n",
    "O exame neurológico é tipicamente normal nas fases iniciais da Doença de Alzheimer, tal como os exames de imagem que, se não forem também regulares, mostram apenas atrofia dos hipocampos, formações anatómicas existentes na parte interna dos hemisférios cerebrais que têm um papel fundamental na consolidação e evocação de novas memórias. Em fases mais avançadas, os doentes desenvolvem muitas vezes sinais de Parkinson (lentidão e rigidez) e os testes mostram atrofia de todo o cérebro.\n",
    "\n",
    "Tratamento\n",
    "Não há cura conhecida para a Doença de Alzheimer, já que a morte das células cerebrais não pode ser revertida. No entanto, existem intervenções terapêuticas que melhoram a vida dos doentes e facilitam o controlo da demência, incluindo:\n",
    "\n",
    "o controlo de outras patologias concomitantes\n",
    "a terapia ocupacional\n",
    "o envolvimento em grupos e serviços de apoio\n",
    "a terapêutica medicamentosa: fármacos que podem reduzir os sintomas e ajudar a melhorar a qualidade de vida dos pacientes- inibidores da colinesterase (donepezilo, rivastigmina, tacrina) e memantina.\n",
    "Os cuidados de apoio nas atividades diárias tornam-se mais importantes à medida que a pessoa é menos capaz de viver de forma independente.\n",
    "\n",
    "Prevenção\n",
    "Existem fatores de risco que não podem ser prevenidos como o envelhecimento, uma história familiar de Alzheimer e a genética. No entanto, há alguns fatores que podem ajudar a prevenir a doença:\n",
    "\n",
    "a atividade física regular\n",
    "a prevenção e tratamento das doenças cardiovasculares (sobretudo o controle da pressão arterial)\n",
    "a prevenção e tratamento da diabetes, da obesidade e tabagismo\n",
    "Em geral, uma dieta variada e saudável e permanecer mental e socialmente ativo pode reduzir o risco de doença de Alzheimer.\"\"\"\n",
    "\n",
    "# Tokenize the input: note that for QA we combine question and context.\n",
    "inputs = tokenizer(question1, context_CUF, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=256)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# The model outputs 'start_logits' and 'end_logits', which represent the probability distribution\n",
    "# for the start and end of the answer span.\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "\n",
    "# Identify the most likely token positions for the start and end of the answer.\n",
    "start_index = torch.argmax(start_logits, dim=1).item()\n",
    "end_index = torch.argmax(end_logits, dim=1).item()\n",
    "\n",
    "# Decode the tokens corresponding to the predicted span.\n",
    "input_ids = inputs[\"input_ids\"].squeeze()\n",
    "answer_tokens = input_ids[start_index:(end_index + 1)]\n",
    "answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "# Output the results.\n",
    "print(\"Question:\", question1)\n",
    "print(\"Predicted Answer:\", answer)"
   ],
   "id": "1bab308e7f4baa37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CALCULATES THE SIMILARITY FROM USER QUESTION AND DATASET QUASETIONS\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# Load MedicalBERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"medicalai/ClinicalBERT\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"medicalai/ClinicalBERT\")\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"\n",
    "    Calculates the embedding for a given text using the MedicalBERT model.\n",
    "\n",
    "    This function tokenizes the input text, runs the model to extract the hidden states,\n",
    "    and then performs mean pooling over the last hidden state to generate a fixed-size embedding.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Enable output_hidden_states so we can use the hidden representations\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "    # Use the last hidden state [batch, sequence_length, hidden_dim]\n",
    "    # and then perform mean pooling over the sequence_length dimension.\n",
    "    last_hidden_state = outputs.hidden_states[-1]\n",
    "    embedding = last_hidden_state.mean(dim=1)  # shape: [batch, hidden_dim]\n",
    "\n",
    "    return embedding.squeeze(0)  # Remove batch dimension for similarity computation\n",
    "\n",
    "# Sample dataset (Extend with your full dataset as needed)\n",
    "dataset = [\n",
    "    {\n",
    "        \"context\": \"Alzheimer's disease (AD) is a neurodegenerative disease that usually starts slowly and progressively worsens. It is the cause of 60–70% of cases of dementia. The most common early symptom is difficulty in remembering recent events.\",\n",
    "        \"qas\": [\n",
    "            {\n",
    "                \"question\": \"What is Alzheimer's disease?\",\n",
    "                \"answers\": [\n",
    "                    {\n",
    "                        \"text\": \"a neurodegenerative disease that usually starts slowly and progressively worsens\",\n",
    "                        \"answer_start\": 22\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"question\": \"What is the most common early symptom of Alzheimer's?\",\n",
    "                \"answers\": [\n",
    "                    {\n",
    "                        \"text\": \"difficulty in remembering recent events\",\n",
    "                        \"answer_start\": 154\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"context\": \"Alzheimer's disease is the most common cause of dementia — a continuous decline in thinking, behavioral and social skills that affects a person's ability to function independently.\",\n",
    "        \"qas\": [\n",
    "            {\n",
    "                \"question\": \"What does Alzheimer's disease cause?\",\n",
    "                \"answers\": [\n",
    "                    {\n",
    "                        \"text\": \"a continuous decline in thinking, behavioral and social skills\",\n",
    "                        \"answer_start\": 53\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"question\": \"How does dementia affect a person?\",\n",
    "                \"answers\": [\n",
    "                    {\n",
    "                        \"text\": \"affects a person's ability to function independently\",\n",
    "                        \"answer_start\": 117\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    # ... add more entries as needed\n",
    "]\n",
    "\n",
    "# User-provided question\n",
    "user_question = \"What are the symptoms of dementia?\"\n",
    "\n",
    "# Calculate the embedding for the user question\n",
    "user_embedding = get_embedding(user_question)\n",
    "\n",
    "# Compute cosine similarity with each question in the dataset and store results\n",
    "results = []\n",
    "for entry in dataset:\n",
    "    context = entry[\"context\"]\n",
    "    for qa in entry[\"qas\"]:\n",
    "        question = qa[\"question\"]\n",
    "        question_embedding = get_embedding(question)\n",
    "        # Compute cosine similarity between the user question embedding and the dataset question embedding\n",
    "        similarity = F.cosine_similarity(user_embedding, question_embedding, dim=0)\n",
    "        results.append({\n",
    "            \"context\": context,\n",
    "            \"question\": question,\n",
    "            \"similarity\": similarity.item()\n",
    "        })\n",
    "\n",
    "# Get the top 3 similar questions (highest cosine similarity)\n",
    "top_results = sorted(results, key=lambda x: x[\"similarity\"], reverse=True)[:3]\n",
    "\n",
    "# Display the top matching contexts, questions, and similarity scores\n",
    "print(\"Top 3 similar questions and their contexts:\")\n",
    "for result in top_results:\n",
    "    print(f\"Similarity: {result['similarity']:.4f}\")\n",
    "    print(f\"Question: {result['question']}\")\n",
    "    print(f\"Context: {result['context']}\\n\")\n"
   ],
   "id": "2d6f043a001d52d9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
